name: Daily Blog â€” Engine Update

on:
  schedule:
    - cron: "0 6 * * *" # 6 AM UTC daily
  workflow_dispatch: # manual trigger for testing

# â”€â”€ Permissions â”€â”€
permissions:
  contents: write
  pull-requests: write
  models: read

# â”€â”€ Concurrency â€” prevent parallel runs â”€â”€
concurrency:
  group: daily-blog
  cancel-in-progress: true

jobs:
  generate:
    # Master kill-switch: set BLOG_ENABLED to 'false' in repo variables to stop
    if: vars.BLOG_ENABLED != 'false'
    runs-on: ubuntu-latest

    steps:
      # â”€â”€ 1. Checkout â”€â”€
      - name: Checkout website frontend
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT || secrets.GITHUB_TOKEN }}

      # â”€â”€ 2. Setup Node â”€â”€
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      # â”€â”€ 3. Compute date window â”€â”€
      - name: Set date variables
        id: dates
        run: |
          echo "today=$(date -u +%Y-%m-%d)" >> "$GITHUB_OUTPUT"
          echo "since=$(date -u -d '24 hours ago' --iso-8601=seconds)" >> "$GITHUB_OUTPUT"
          echo "display=$(date -u +'%b %d, %Y')" >> "$GITHUB_OUTPUT"

      # â”€â”€ 4. Check for existing post (avoid duplicates) â”€â”€
      - name: Check for existing post
        id: existing
        run: |
          SLUG="${{ steps.dates.outputs.today }}-engine-daily-update"
          if [ -f "content/blog/${SLUG}.md" ]; then
            echo "exists=true" >> "$GITHUB_OUTPUT"
          else
            echo "exists=false" >> "$GITHUB_OUTPUT"
          fi

      # â”€â”€ 5. Fetch project activity from tracked repos â”€â”€
      - name: Fetch project activity
        if: steps.existing.outputs.exists == 'false'
        id: activity
        env:
          GH_TOKEN: ${{ secrets.GH_PAT || secrets.GITHUB_TOKEN }}
          BLOG_MAX_COMMITS: ${{ vars.BLOG_MAX_COMMITS || '30' }}
          BLOG_MAX_MERGED_PRS: ${{ vars.BLOG_MAX_MERGED_PRS || '15' }}
          BLOG_MAX_OPEN_PRS: ${{ vars.BLOG_MAX_OPEN_PRS || '20' }}
          BLOG_MAX_ISSUES: ${{ vars.BLOG_MAX_ISSUES || '15' }}
        run: |
          REPOS=(
            "rivie13/Phoenix-Agentic-Engine"
            "rivie13/Phoenix-Agentic-Website-Frontend"
            "rivie13/Phoenix-Agentic-Engine-Interface"
          )
          SINCE="${{ steps.dates.outputs.since }}"
          # Derive YYYY-MM-DD from the SINCE timestamp so the 24h window is fully covered.
          # Using today's date would miss commits made yesterday after SINCE but before midnight.
          SINCE_DATE=$(echo "${SINCE}" | cut -c1-10)

          ALL_COMMITS='[]'
          ALL_PRS='[]'
          ALL_ISSUES='[]'

          for REPO in "${REPOS[@]}"; do
            echo "Fetching activity for ${REPO}..."

            # Use commit SEARCH API â€” queries ALL branches, not just default branch.
            # The regular /repos/.../commits endpoint only searches the default branch.
            # Note: the search API does not expose which branch a commit is on, so we omit that field.
            COMMITS=$(gh api \
              -H "Accept: application/vnd.github.cloak-preview" \
              "search/commits?q=repo:${REPO}+committer-date:>=${SINCE_DATE}&sort=committer-date&order=desc&per_page=50" \
              --jq "[.items[] | {repo: \"${REPO}\", sha: .sha[0:7], message: .commit.message | split(\"\\n\")[0], author: .commit.author.name, url: .html_url}]")

            # Fetch PRs updated in window, then split into merged vs open for clear AI consumption.
            REPO_PRS=$(gh api "repos/${REPO}/pulls?state=all&sort=updated&direction=desc&per_page=30" \
              --jq "[.[] | select(.updated_at >= \"${SINCE}\") | {repo: \"${REPO}\", number, title, state, draft, user: .user.login, url: .html_url, updated_at: .updated_at, merged: (.merged_at != null), head_ref: .head.ref, base_ref: .base.ref, body_excerpt: ((.body // \"\") | gsub(\"\\r|\\n\"; \" \") | gsub(\" +\"; \" \") | .[0:500])}]")

            ISSUES=$(gh api "repos/${REPO}/issues?state=all&sort=updated&since=${SINCE}&per_page=30" \
              --jq "[.[] | select(.pull_request == null) | {repo: \"${REPO}\", number, title, state, user: .user.login, url: .html_url}]")

            ALL_COMMITS=$(jq -c -n --argjson current "$ALL_COMMITS" --argjson extra "$COMMITS" '$current + $extra')
            ALL_PRS=$(jq -c -n --argjson current "$ALL_PRS" --argjson extra "$REPO_PRS" '$current + $extra')
            ALL_ISSUES=$(jq -c -n --argjson current "$ALL_ISSUES" --argjson extra "$ISSUES" '$current + $extra')
          done

          MERGED_PRS=$(echo "$ALL_PRS" | jq '[.[] | select(.merged == true)]')
          OPEN_PRS=$(echo "$ALL_PRS" | jq '[.[] | select(.merged == false)]')

          # Count items
          COMMIT_COUNT=$(echo "$ALL_COMMITS" | jq 'length')
          MERGED_PR_COUNT=$(echo "$MERGED_PRS" | jq 'length')
          OPEN_PR_COUNT=$(echo "$OPEN_PRS" | jq 'length')
          ISSUE_COUNT=$(echo "$ALL_ISSUES" | jq 'length')
          TOTAL=$((COMMIT_COUNT + MERGED_PR_COUNT + OPEN_PR_COUNT + ISSUE_COUNT))

          echo "Found across tracked repos: ${COMMIT_COUNT} commits (all branches), ${MERGED_PR_COUNT} merged PRs, ${OPEN_PR_COUNT} open PRs, ${ISSUE_COUNT} issues"

          if [ "$TOTAL" -eq 0 ]; then
            echo "has_activity=false" >> "$GITHUB_OUTPUT"
            echo "No activity found â€” skipping blog post."
          else
            echo "has_activity=true" >> "$GITHUB_OUTPUT"

            # Write full activity payload (includes totals + full arrays).
            jq -n \
              --arg since "$SINCE" \
              --argjson commits "$ALL_COMMITS" \
              --argjson merged_prs "$MERGED_PRS" \
              --argjson open_prs "$OPEN_PRS" \
              --argjson issues "$ALL_ISSUES" \
              --arg commit_count "$COMMIT_COUNT" \
              --arg merged_pr_count "$MERGED_PR_COUNT" \
              --arg open_pr_count "$OPEN_PR_COUNT" \
              --arg issue_count "$ISSUE_COUNT" \
              '{
                meta: {
                  window_since: $since,
                  totals: {
                    commits: ($commit_count | tonumber),
                    merged_prs: ($merged_pr_count | tonumber),
                    open_prs: ($open_pr_count | tonumber),
                    issues: ($issue_count | tonumber)
                  },
                  note: "Full payload. Compact and ultra payloads are available as fallback tiers."
                },
                commits: $commits,
                merged_prs: $merged_prs,
                open_prs: $open_prs,
                issues: $issues
              }' > /tmp/activity.json

            # Build token-budgeted compact payload for model calls.
            COMMIT_HIGHLIGHTS=$(echo "$ALL_COMMITS" | jq --arg n "$BLOG_MAX_COMMITS" '.[0:($n|tonumber)]')
            MERGED_PR_HIGHLIGHTS=$(echo "$MERGED_PRS" | jq --arg n "$BLOG_MAX_MERGED_PRS" '.[0:($n|tonumber)]')
            OPEN_PR_HIGHLIGHTS=$(echo "$OPEN_PRS" | jq --arg n "$BLOG_MAX_OPEN_PRS" '.[0:($n|tonumber)]')
            ISSUE_HIGHLIGHTS=$(echo "$ALL_ISSUES" | jq --arg n "$BLOG_MAX_ISSUES" '.[0:($n|tonumber)]')

            jq -n \
              --arg since "$SINCE" \
              --argjson commits "$COMMIT_HIGHLIGHTS" \
              --argjson merged_prs "$MERGED_PR_HIGHLIGHTS" \
              --argjson open_prs "$OPEN_PR_HIGHLIGHTS" \
              --argjson issues "$ISSUE_HIGHLIGHTS" \
              --arg commit_count "$COMMIT_COUNT" \
              --arg merged_pr_count "$MERGED_PR_COUNT" \
              --arg open_pr_count "$OPEN_PR_COUNT" \
              --arg issue_count "$ISSUE_COUNT" \
              '{
                meta: {
                  window_since: $since,
                  totals: {
                    commits: ($commit_count | tonumber),
                    merged_prs: ($merged_pr_count | tonumber),
                    open_prs: ($open_pr_count | tonumber),
                    issues: ($issue_count | tonumber)
                  },
                  note: "Arrays are intentionally truncated for token safety. Use totals for full counts."
                },
                commits: $commits,
                merged_prs: $merged_prs,
                open_prs: $open_prs,
                issues: $issues
              }' > /tmp/activity-compact.json

            # Ultra-compact fallback payload for very small-context models.
            jq -n \
              --argjson commits "$(echo "$ALL_COMMITS" | jq '.[0:12]')" \
              --argjson merged_prs "$(echo "$MERGED_PRS" | jq '.[0:8]')" \
              --argjson open_prs "$(echo "$OPEN_PRS" | jq '.[0:10]')" \
              --argjson issues "$(echo "$ALL_ISSUES" | jq '.[0:8]')" \
              --arg commit_count "$COMMIT_COUNT" \
              --arg merged_pr_count "$MERGED_PR_COUNT" \
              --arg open_pr_count "$OPEN_PR_COUNT" \
              --arg issue_count "$ISSUE_COUNT" \
              '{
                meta: {
                  totals: {
                    commits: ($commit_count | tonumber),
                    merged_prs: ($merged_pr_count | tonumber),
                    open_prs: ($open_pr_count | tonumber),
                    issues: ($issue_count | tonumber)
                  },
                  note: "Ultra-compact fallback payload for strict token windows."
                },
                commits: $commits,
                merged_prs: $merged_prs,
                open_prs: $open_prs,
                issues: $issues
              }' > /tmp/activity-ultra.json

            echo "Activity payloads written: /tmp/activity.json (full), /tmp/activity-compact.json, /tmp/activity-ultra.json"
          fi

      # â”€â”€ 6. Generate blog post (Pollinations-first, GitHub fallback) â”€â”€
      - name: Generate blog post
        if: steps.existing.outputs.exists == 'false' && steps.activity.outputs.has_activity == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          POLLINATIONS_API_KEY: ${{ secrets.POLLINATIONS_API_KEY }}
          BLOG_TEXT_PROVIDER: ${{ vars.BLOG_TEXT_PROVIDER || 'pollinations' }}
          BLOG_TEXT_MODEL_GITHUB: ${{ vars.BLOG_TEXT_MODEL_GITHUB || 'openai/gpt-5-chat' }}
          BLOG_TEXT_MODEL_GITHUB_FALLBACK: ${{ vars.BLOG_TEXT_MODEL_GITHUB_FALLBACK || '' }}
          BLOG_TEXT_MODEL_POLLINATIONS: ${{ vars.BLOG_TEXT_MODEL_POLLINATIONS || 'openai' }}
          BLOG_TEXT_MODEL_POLLINATIONS_FALLBACK: ${{ vars.BLOG_TEXT_MODEL_POLLINATIONS_FALLBACK || 'openai-fast' }}
        run: |
          SLUG="${{ steps.dates.outputs.today }}-engine-daily-update"
          SYSTEM_PROMPT=$(cat prompts/daily-blog-system.md)
          ACTIVITY_FULL_FILE="/tmp/activity.json"
          ACTIVITY_LIMITED_FILE="/tmp/activity-compact.json"
          ACTIVITY_ULTRA_FILE="/tmp/activity-ultra.json"

          TEXT_PROVIDER=$(echo "${BLOG_TEXT_PROVIDER}" | tr '[:upper:]' '[:lower:]')
          WRITER_MODEL_GITHUB="${BLOG_TEXT_MODEL_GITHUB}"
          WRITER_MODEL_GITHUB_FALLBACK="${BLOG_TEXT_MODEL_GITHUB_FALLBACK}"
          WRITER_MODEL_POLLINATIONS="${BLOG_TEXT_MODEL_POLLINATIONS}"
          WRITER_MODEL_POLLINATIONS_FALLBACK="${BLOG_TEXT_MODEL_POLLINATIONS_FALLBACK}"

          POLLINATIONS_KEY=$(echo "${POLLINATIONS_API_KEY}" | sed -E 's/^[[:space:]]+|[[:space:]]+$//g')
          POLLINATIONS_KEY=$(echo "${POLLINATIONS_KEY}" | sed -E 's/^[Bb]earer[[:space:]]+//')

          build_user_message() {
            local activity_file="$1"
            local payload_note="$2"
            local activity_payload=""
            activity_payload=$(cat "$activity_file")
            printf "Today's date: ${{ steps.dates.outputs.display }}\nDate (ISO): ${{ steps.dates.outputs.today }}\nSlug: %s\n\nPayload tier: %s\n\nHere is today's tracked-repo activity data (JSON):\n\n%s\n\nImportant:\n- Use meta.totals for full counts.\n- Arrays may be truncated intentionally for token safety.\n- Prioritize the most technically meaningful items and avoid filler.\n" "$SLUG" "$payload_note" "$activity_payload"
          }

          call_text_model() {
            local provider="$1"
            local model="$2"
            local user_message="$3"

            if [ "$provider" = "pollinations" ]; then
              if [ -z "$POLLINATIONS_KEY" ]; then
                echo "::error::BLOG_TEXT_PROVIDER=pollinations but POLLINATIONS_API_KEY is missing"
                return 1
              fi

              curl -sS https://gen.pollinations.ai/v1/chat/completions \
                -H "Authorization: Bearer ${POLLINATIONS_KEY}" \
                -H "Content-Type: application/json" \
                -d "$(jq -n \
                  --arg model "$model" \
                  --arg system "$SYSTEM_PROMPT" \
                  --arg user "$user_message" \
                  '{
                    model: $model,
                    messages: [
                      {role: "system", content: $system},
                      {role: "user", content: $user}
                    ],
                    temperature: 0.7,
                    max_tokens: 2000
                  }')"
              return $?
            fi

            curl -sS https://models.github.ai/inference/chat/completions \
              -H "Accept: application/vnd.github+json" \
              -H "X-GitHub-Api-Version: 2022-11-28" \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer ${GH_TOKEN}" \
              -d "$(jq -n \
                --arg model "$model" \
                --arg system "$SYSTEM_PROMPT" \
                --arg user "$user_message" \
                '{
                  model: $model,
                  messages: [
                    {role: "system", content: $system},
                    {role: "user", content: $user}
                  ],
                  temperature: 0.7,
                  max_tokens: 2000
                }')"
          }

          get_content() {
            echo "$1" | jq -r '.choices[0].message.content // empty'
          }

          get_error_code() {
            echo "$1" | jq -r '.error.code // .error.type // empty'
          }

          get_error_message() {
            echo "$1" | jq -r '.error.message // empty'
          }

          is_context_error() {
            local code="$1"
            local message="$2"
            echo "${code} ${message}" | grep -Eiq 'context|token|length|max.*(token|context)|prompt.*(too long|exceed)'
          }

          is_auth_error() {
            local code="$1"
            local message="$2"
            echo "${code} ${message}" | grep -Eiq 'unauthorized|invalid_api_key|forbidden|authentication|auth|key'
          }

          attempt_generation() {
            local provider="$1"
            local model="$2"
            local activity_file="$3"
            local payload_label="$4"

            if [ -z "$model" ]; then
              return 1
            fi

            USER_MESSAGE=$(build_user_message "$activity_file" "$payload_label")
            RESPONSE=$(call_text_model "$provider" "$model" "$USER_MESSAGE") || RESPONSE=""

            CONTENT=$(get_content "$RESPONSE")
            ERROR_CODE=$(get_error_code "$RESPONSE")
            ERROR_MESSAGE=$(get_error_message "$RESPONSE")

            if [ -n "$CONTENT" ]; then
              MODEL_USED="$model"
              PROVIDER_USED="$provider"
              PAYLOAD_USED="$payload_label"
              return 0
            fi

            if [ -n "$ERROR_CODE" ] || [ -n "$ERROR_MESSAGE" ]; then
              echo "::warning::Text generation failed (provider=${provider}, model=${model}, payload=${payload_label}, code=${ERROR_CODE}, message=${ERROR_MESSAGE})"
            fi

            return 1
          }

          run_provider_chain() {
            local provider="$1"
            local primary_model="$2"
            local fallback_model="$3"

            local payload_files=("$ACTIVITY_FULL_FILE" "$ACTIVITY_LIMITED_FILE" "$ACTIVITY_ULTRA_FILE")
            local payload_labels=("full" "limited" "ultra")

            for i in 0 1 2; do
              local payload_file="${payload_files[$i]}"
              local payload_label="${payload_labels[$i]}"

              if attempt_generation "$provider" "$primary_model" "$payload_file" "$payload_label"; then
                return 0
              fi

              if is_auth_error "$ERROR_CODE" "$ERROR_MESSAGE"; then
                echo "::warning::Stopping provider '${provider}' due to auth/key error and moving to cross-provider fallback."
                return 1
              fi

              if [ -n "$fallback_model" ] && [ "$fallback_model" != "$primary_model" ]; then
                if attempt_generation "$provider" "$fallback_model" "$payload_file" "$payload_label"; then
                  return 0
                fi

                if is_auth_error "$ERROR_CODE" "$ERROR_MESSAGE"; then
                  echo "::warning::Stopping provider '${provider}' due to auth/key error on fallback model and moving to cross-provider fallback."
                  return 1
                fi
              fi
            done

            return 1
          }

          CONTENT=""
          MODEL_USED=""
          PROVIDER_USED=""
          PAYLOAD_USED=""
          ERROR_CODE=""
          ERROR_MESSAGE=""

          if [ "$TEXT_PROVIDER" = "github" ]; then
            PRIMARY_PROVIDER="github"
            SECONDARY_PROVIDER="pollinations"
          else
            PRIMARY_PROVIDER="pollinations"
            SECONDARY_PROVIDER="github"
          fi

          if [ "$PRIMARY_PROVIDER" = "pollinations" ]; then
            run_provider_chain "pollinations" "$WRITER_MODEL_POLLINATIONS" "$WRITER_MODEL_POLLINATIONS_FALLBACK" || true
            if [ -z "$CONTENT" ]; then
              echo "::warning::Pollinations provider exhausted payload tiers. Falling back to GitHub Models."
              run_provider_chain "github" "$WRITER_MODEL_GITHUB" "$WRITER_MODEL_GITHUB_FALLBACK" || true
            fi
          else
            run_provider_chain "github" "$WRITER_MODEL_GITHUB" "$WRITER_MODEL_GITHUB_FALLBACK" || true
            if [ -z "$CONTENT" ]; then
              echo "::warning::GitHub provider exhausted payload tiers. Falling back to Pollinations."
              run_provider_chain "pollinations" "$WRITER_MODEL_POLLINATIONS" "$WRITER_MODEL_POLLINATIONS_FALLBACK" || true
            fi
          fi

          if [ -z "$CONTENT" ]; then
            echo "::error::AI generation failed â€” no content returned after provider and payload fallbacks"
            if is_auth_error "$ERROR_CODE" "$ERROR_MESSAGE"; then
              if [ "$PRIMARY_PROVIDER" = "pollinations" ]; then
                echo "::error::Pollinations auth likely failed and fallback also did not produce content. Check POLLINATIONS_API_KEY and provider access."
              else
                echo "::error::GitHub Models auth likely failed and fallback also did not produce content. Check workflow permissions and model access."
              fi
            fi
            if [ -n "$ERROR_MESSAGE" ]; then
              echo "::error::Last provider error: ${ERROR_MESSAGE}"
            fi
            echo "$RESPONSE" | jq .
            exit 1
          fi

          if is_context_error "$ERROR_CODE" "$ERROR_MESSAGE"; then
            echo "::notice::Recovered generation despite context pressure using payload tier '${PAYLOAD_USED}'."
          fi

          if [ -z "$MODEL_USED" ] || [ -z "$PROVIDER_USED" ] || [ -z "$PAYLOAD_USED" ]; then
            echo "::warning::Generation metadata missing; content exists but provider/model/payload tracking is incomplete."
          else
            echo "Generated blog content via provider=${PROVIDER_USED} model=${MODEL_USED} payload=${PAYLOAD_USED}"
          fi

          if [ -z "$RESPONSE" ]; then
            RESPONSE='{}'
          fi

          # Keep compatibility with downstream logic expecting these symbols.
          TEXT_PROVIDER="$PROVIDER_USED"

          if [ -n "$ERROR_CODE" ] || [ -n "$ERROR_MESSAGE" ]; then
            if [ "$PROVIDER_USED" = "github" ] && is_auth_error "$ERROR_CODE" "$ERROR_MESSAGE"; then
              echo "::warning::GitHub Models reported auth-related issues during fallback attempts."
            fi

            if [ "$PROVIDER_USED" = "pollinations" ] && is_auth_error "$ERROR_CODE" "$ERROR_MESSAGE"; then
              echo "::warning::Pollinations reported auth-related issues during fallback attempts."
            fi
          fi

          if [ -z "$CONTENT" ]; then
            echo "::error::AI generation failed â€” no content returned (provider=${TEXT_PROVIDER}, model=${MODEL_USED})"
            if is_auth_error "$ERROR_CODE" "$ERROR_MESSAGE"; then
              if [ "$TEXT_PROVIDER" = "github" ]; then
                echo "::error::GitHub Models auth failed. Ensure workflow has 'permissions: models: read' and Models access is enabled in repository settings."
              else
                echo "::error::Pollinations auth failed. Ensure POLLINATIONS_API_KEY is valid and has pollen balance."
              fi
            fi
            if [ -n "$ERROR_MESSAGE" ]; then
              echo "::error::Provider error: ${ERROR_MESSAGE}"
            fi
            echo "$RESPONSE" | jq .
            exit 1
          fi

          # If generation succeeded with limited/ultra, continue normally.
          if [ "$PAYLOAD_USED" = "limited" ] || [ "$PAYLOAD_USED" = "ultra" ]; then
            echo "::notice::Generation completed using '${PAYLOAD_USED}' payload tier."
          fi

          if [ "$PROVIDER_USED" = "" ]; then
            PROVIDER_USED="$TEXT_PROVIDER"
          fi

          if [ "$MODEL_USED" = "" ]; then
            if [ "$PROVIDER_USED" = "pollinations" ]; then
              MODEL_USED="$WRITER_MODEL_POLLINATIONS"
            else
              MODEL_USED="$WRITER_MODEL_GITHUB"
            fi
          fi

          # Split content into blog post and image prompt
          BLOG_POST_RAW=$(echo "$CONTENT" | sed '/^<!-- IMAGE_PROMPT -->/,$d')
          IMAGE_PROMPT=$(echo "$CONTENT" | awk '/^<!-- IMAGE_PROMPT -->/{flag=1; next} flag{print}' | sed -E '/^[[:space:]]*```[[:alnum:]_-]*[[:space:]]*$/d; /^[[:space:]]*$/d' | head -1)
          HAS_IMAGE_PROMPT_MARKER=false
          if echo "$CONTENT" | grep -q '^<!-- IMAGE_PROMPT -->'; then
            HAS_IMAGE_PROMPT_MARKER=true
          fi

          if [ "$HAS_IMAGE_PROMPT_MARKER" = "true" ] && [ -z "$IMAGE_PROMPT" ]; then
            echo "::error::Generated content contains <!-- IMAGE_PROMPT --> but no valid non-empty image prompt line after it"
            echo "::error::First 20 lines of raw AI output:"
            echo "$CONTENT" | head -n 20
            exit 1
          fi

          # Normalize generated markdown so frontmatter starts at line 1.
          # This prevents accidental wrappers like ```markdown ... ``` from being written into the blog file.
          BLOG_POST=$(echo "$BLOG_POST_RAW" | sed 's/\r$//' | awk '
            BEGIN { started = 0 }
            {
              if (started == 0) {
                if ($0 ~ /^```[[:alnum:]_-]*[[:space:]]*$/) next
                if ($0 ~ /^---$/) { started = 1; print; next }
                next
              }

              if ($0 ~ /^```[[:alnum:]_-]*[[:space:]]*$/) next
              print
            }
          ')

          if ! echo "$BLOG_POST" | head -n 1 | grep -q '^---$'; then
            echo "::error::Generated blog post does not start with YAML frontmatter delimiter ('---')"
            echo "::error::First 5 lines of sanitized output:"
            echo "$BLOG_POST" | head -n 5
            exit 1
          fi

          FRONTMATTER_CLOSE_LINE=$(echo "$BLOG_POST" | awk 'NR > 1 && /^---$/ { print NR; exit }')
          if [ -z "$FRONTMATTER_CLOSE_LINE" ]; then
            echo "::error::Generated blog post frontmatter is missing closing YAML delimiter ('---')"
            echo "::error::First 20 lines of sanitized output:"
            echo "$BLOG_POST" | head -n 20
            exit 1
          fi

          # Write blog post
          mkdir -p content/blog
          printf "%s" "$BLOG_POST" > "content/blog/${SLUG}.md"
          echo "Blog post written to content/blog/${SLUG}.md"

          # Save image prompt for next step
          if [ -n "$IMAGE_PROMPT" ]; then
            echo "$IMAGE_PROMPT" > /tmp/image-prompt.txt
            echo "image_prompt_exists=true" >> "$GITHUB_OUTPUT"
          else
            echo "image_prompt_exists=false" >> "$GITHUB_OUTPUT"
          fi

          echo "slug=${SLUG}" >> "$GITHUB_OUTPUT"

      # â”€â”€ 7. Generate hero image via Pollinations.ai (authenticated gen endpoint) â”€â”€
      - name: Generate hero image
        if: >
          steps.existing.outputs.exists == 'false' &&
          steps.activity.outputs.has_activity == 'true' &&
          vars.BLOG_IMAGE_ENABLED != 'false'
        env:
          POLLINATIONS_API_KEY: ${{ secrets.POLLINATIONS_API_KEY }}
        run: |
          SLUG="${{ steps.dates.outputs.today }}-engine-daily-update"

          if [ -f /tmp/image-prompt.txt ]; then
            PROMPT=$(cat /tmp/image-prompt.txt)
          else
            PROMPT="Abstract digital art, dark background, glowing orange phoenix rising over circuit board patterns, futuristic game engine theme, no text"
          fi

          ENCODED_PROMPT=$(python3 -c "import urllib.parse, sys; print(urllib.parse.quote(sys.stdin.read().strip()))" <<< "$PROMPT")
          POLLINATIONS_GEN_BASE="https://gen.pollinations.ai/image/${ENCODED_PROMPT}?width=1792&height=1024&nologo=true"

          API_KEY=$(echo "${POLLINATIONS_API_KEY}" | sed -E 's/^[[:space:]]+|[[:space:]]+$//g')
          API_KEY=$(echo "${API_KEY}" | sed -E 's/^[Bb]earer[[:space:]]+//')

          if [ -z "${API_KEY}" ]; then
            echo "::warning::POLLINATIONS_API_KEY is missing. Skipping AI hero generation and using Phoenix logo fallback."
            sed -i "s|/images/blog/${SLUG}.png|/images/phoenix-icon.png|" "content/blog/${SLUG}.md"
            echo "Using Phoenix logo as hero image."
            exit 0
          fi

          AUTH_ARGS=(-H "Authorization: Bearer ${API_KEY}")

          KEY_STATUS=$(curl -sS "https://gen.pollinations.ai/account/key" \
            "${AUTH_ARGS[@]}" \
            -H "Accept: application/json" \
            -o /tmp/pollinations-key-status.json \
            -w "%{http_code}") || KEY_STATUS="000"

          if [ "${KEY_STATUS}" != "200" ]; then
            KEY_ERROR=$(jq -r '.error.message // .message // empty' /tmp/pollinations-key-status.json 2>/dev/null || true)
            if [ -z "${KEY_ERROR}" ]; then
              KEY_ERROR="Unable to validate Pollinations API key."
            fi
            echo "::warning::Pollinations key validation failed (HTTP ${KEY_STATUS}). ${KEY_ERROR} Falling back to Phoenix logo."
            sed -i "s|/images/blog/${SLUG}.png|/images/phoenix-icon.png|" "content/blog/${SLUG}.md"
            echo "Using Phoenix logo as hero image."
            exit 0
          fi

          echo "Using authenticated Pollinations image generation."

          fetch_pollinations_image() {
            local base_url="$1"
            local model="$2"
            local source_label="$3"
            local attempt=""
            local http_status=""
            local response_file=""
            local error_message=""

            for attempt in 1 2 3; do
              echo "Attempt ${attempt}/3 via ${source_label} (model: ${model})..."
              response_file=$(mktemp)
              http_status=$(curl -sSL \
                "${base_url}&model=${model}" \
                "${AUTH_ARGS[@]}" \
                -A "PhoenixBlogBot/1.0 (+https://phoenixengine.dev)" \
                --retry 2 \
                --retry-delay 2 \
                --retry-connrefused \
                --max-time 120 \
                -o "${response_file}" \
                -w "%{http_code}") || http_status="000"

              if [ "$http_status" = "200" ] && [ -s "${response_file}" ]; then
                mv "${response_file}" "public/images/blog/${SLUG}.png"
                echo "âœ“ Hero image saved (${source_label}, ${model}) â†’ public/images/blog/${SLUG}.png"
                return 0
              fi

              error_message=$(jq -r '.error.message // .message // empty' "${response_file}" 2>/dev/null || true)
              rm -f "${response_file}" "public/images/blog/${SLUG}.png"

              if [ "$http_status" = "500" ] || [ "$http_status" = "502" ] || [ "$http_status" = "503" ] || [ "$http_status" = "504" ] || [ "$http_status" = "522" ] || [ "$http_status" = "524" ] || [ "$http_status" = "530" ] || [ "$http_status" = "000" ]; then
                echo "Transient error (HTTP ${http_status}) from ${source_label}; retrying..."
                sleep $((attempt * 2))
              else
                if [ -n "${error_message}" ]; then
                  echo "::warning::${source_label} returned HTTP ${http_status} for model ${model}: ${error_message}"
                fi
                break
              fi
            done

            echo "::warning::${source_label} failed for model ${model} (last HTTP ${http_status})"
            return 1
          }

          mkdir -p public/images/blog
          IMAGE_SAVED=false

          # â”€â”€ Tier 1: Authenticated unified endpoint (gen.pollinations.ai) â”€â”€
          if fetch_pollinations_image "${POLLINATIONS_GEN_BASE}" "flux" "gen.pollinations.ai"; then
            IMAGE_SAVED=true
          elif fetch_pollinations_image "${POLLINATIONS_GEN_BASE}" "turbo" "gen.pollinations.ai"; then
            IMAGE_SAVED=true
          fi

          # â”€â”€ Tier 3: Phoenix logo fallback â”€â”€
          if [ "$IMAGE_SAVED" = "false" ]; then
            echo "::warning::All Pollinations attempts failed â€” using Phoenix logo fallback"
            sed -i "s|/images/blog/${SLUG}.png|/images/phoenix-icon.png|" "content/blog/${SLUG}.md"
            echo "Using Phoenix logo as hero image."
          fi

      # â”€â”€ 8. Create PR (Phoenix Website Frontend) â”€â”€
      - name: Create pull request
        if: steps.existing.outputs.exists == 'false' && steps.activity.outputs.has_activity == 'true'
        env:
          GH_TOKEN: ${{ secrets.GH_PAT || secrets.GITHUB_TOKEN }}
        run: |
          SLUG="${{ steps.dates.outputs.today }}-engine-daily-update"
          BRANCH="blog/${SLUG}"
          DATE_DISPLAY="${{ steps.dates.outputs.display }}"

          git config user.name "Phoenix Blog Bot"
          git config user.email "blog-bot@phoenix-engine.dev"

          git checkout -b "${BRANCH}"
          git add content/blog/
          if [ -d "public/images/blog" ] && [ -n "$(ls -A public/images/blog 2>/dev/null)" ]; then
            git add public/images/blog/
          fi
          git commit -m "blog: engine daily update â€” ${DATE_DISPLAY}"
          git push origin "${BRANCH}"

          # Build PR body
          PR_BODY="## ðŸ¤– Automated Daily Blog Post

          **Date**: ${DATE_DISPLAY}
          **Source**: Engine repo activity from the last 24 hours

          ### Preview

          $(head -30 "content/blog/${SLUG}.md" | tail -20)

          ---

          *This PR was automatically generated. Review the post content and merge when ready.*
          *Social posts (Bluesky/LinkedIn) will be triggered after merge if enabled.*"

          gh pr create \
            --title "blog: engine daily update â€” ${DATE_DISPLAY}" \
            --body "$PR_BODY" \
            --base main \
            --head "${BRANCH}" \
            --label "blog,automated"

      # â”€â”€ 9. Cross-post to GitHub Pages (Jekyll) â”€â”€
      # Toggle: set BLOG_CROSSPOST_GITHUB_PAGES to 'true' in repo variables when ready
      - name: Cross-post to GitHub Pages (Jekyll)
        if: >
          steps.existing.outputs.exists == 'false' &&
          steps.activity.outputs.has_activity == 'true' &&
          vars.BLOG_CROSSPOST_GITHUB_PAGES == 'true'
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          SLUG="${{ steps.dates.outputs.today }}-engine-daily-update"
          DATE="${{ steps.dates.outputs.today }}"
          DATE_DISPLAY="${{ steps.dates.outputs.display }}"
          JEKYLL_FILENAME="${DATE}-phoenix-engine-update.md"

          # Read the body of the generated post (strip front matter, keep body)
          BODY=$(awk '/^---$/{if(++n==2){found=1; next}} found{print}' "content/blog/${SLUG}.md")

          # Read summary from front matter
          SUMMARY=$(grep '^summary:' "content/blog/${SLUG}.md" | sed 's/^summary: *"//;s/"$//')
          TITLE=$(grep '^title:' "content/blog/${SLUG}.md" | sed 's/^title: *"//;s/"$//')

          # Build Jekyll front matter
          JEKYLL_POST="---
          layout: post
          title: \"${TITLE}\"
          date: ${DATE} 06:00:00 +0000
          categories: [Phoenix, Engine]
          tags: [phoenix-engine, game-dev, godot, ai, daily-update]
          author: Phoenix Blog Bot
          ai_generated: true
          excerpt: \"${SUMMARY}\"
          image: /assets/images/blog-social-image.png
          ---

          > **Automated post** â€” This post was automatically generated by AI from Phoenix Engine activity data. [Read on the Phoenix website](https://phoenixengine.dev/blog/${SLUG}) for the full version with hero image.

          ${BODY}"

          # Push directly to the GitHub Pages repo via API
          # Encode content as base64
          CONTENT_B64=$(echo "$JEKYLL_POST" | base64 -w 0)

          # Check if the file already exists to get its SHA (needed for updates)
          EXISTING=$(gh api "repos/rivie13/rivie13.github.io/contents/_posts/phoenix/${JEKYLL_FILENAME}" \
            --jq '.sha // empty' 2>/dev/null || true)

          if [ -n "$EXISTING" ]; then
            echo "File already exists in GitHub Pages repo â€” skipping"
          else
            # Create the file (no SHA needed for creation).
            PAYLOAD=$(jq -n \
              --arg msg "blog: phoenix engine update â€” ${DATE_DISPLAY}" \
              --arg content "$CONTENT_B64" \
              '{message: $msg, content: $content}')

            gh api "repos/rivie13/rivie13.github.io/contents/_posts/phoenix/${JEKYLL_FILENAME}" \
              --method PUT \
              --input <(echo "$PAYLOAD")

            echo "âœ“ Cross-posted to rivie13.github.io/_posts/phoenix/${JEKYLL_FILENAME}"
          fi
